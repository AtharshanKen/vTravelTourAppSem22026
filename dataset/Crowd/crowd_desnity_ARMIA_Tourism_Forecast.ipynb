{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3e116",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "- Produces Crowd Predicitions based on weather and user selected location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd456dd",
   "metadata": {},
   "source": [
    "### Load the Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebb45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from pmdarima import AutoARIMA,auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime,timedelta,date\n",
    "import holidays as hl\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "str_trim_date = pd.to_datetime('2021-01-01').to_datetime64()# The start of the dataset\n",
    "end_trim_date = pd.to_datetime('2025-12-31').to_datetime64()# The end of the dataset, shouldn't assume both actual end at this date for each location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0fcfb",
   "metadata": {},
   "source": [
    "### Load the data set ensure both the dataframe date range and date are in correct format for ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auck_peds = pd.read_csv(\"data_weather/Final/Auckland_Pedestrian_daily.csv\")\n",
    "Dub_peds = pd.read_csv(\"data_weather/Final/Dublin_Pedestrian_daily.csv\")\n",
    "\n",
    "df = pd.concat([Auck_peds, Dub_peds],ignore_index=True)\n",
    "\n",
    "df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x).to_datetime64())\n",
    "df = df.sort_values(['Location_ID','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6258390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['2021-01-01T00:00:00.000000000', '2021-01-02T00:00:00.000000000',\n",
       "        '2021-01-03T00:00:00.000000000', ...,\n",
       "        '2025-12-29T00:00:00.000000000', '2025-12-30T00:00:00.000000000',\n",
       "        '2025-12-31T00:00:00.000000000'], dtype='datetime64[ns]')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df['Date'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f310aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([numpy.datetime64('2025-12-31T00:00:00.000000000')],\n",
       " [numpy.datetime64('2021-01-01T00:00:00.000000000')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[end_trim_date],[str_trim_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120d01",
   "metadata": {},
   "source": [
    "### Main ARIMA model\n",
    "- Model creation\n",
    "- Data splitting\n",
    "- Fitting model\n",
    "- Creates pickel files for each location\n",
    "    - Need seperate pickel files for forecasting each location \n",
    "- ARMIA needs to have even spacing between dates\n",
    "    if gap then a fill in needs to be done for Y values(Dep Var) & Exog(or X Ind Vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37acacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdc52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRDUB_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 29837.186134756066\n",
      "RMSE: 34039.26421512039\n",
      "R²  : -0.9658717563983943\n",
      "IRDUB_3\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 19541.61752037991\n",
      "RMSE: 22607.9197058463\n",
      "R²  : -0.6304377491782609\n",
      "IRDUB_4\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 34093.33357693659\n",
      "RMSE: 37793.12908592663\n",
      "R²  : -1.4235629257731315\n",
      "IRDUB_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 6552.58370033953\n",
      "RMSE: 8231.950642068556\n",
      "R²  : -0.04885236995479558\n",
      "IRDUB_8\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 148875.5106587343\n",
      "RMSE: 159719.5768715072\n",
      "R²  : -4.211952689184148\n",
      "NZAUK_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 5425.248238521027\n",
      "RMSE: 6775.7094105483075\n",
      "R²  : 0.562236912270189\n",
      "NZAUK_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 10123.085829200445\n",
      "RMSE: 13115.413430050161\n",
      "R²  : 0.6593792550327102\n",
      "NZAUK_6\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 6321.113906009278\n",
      "RMSE: 7859.292756508167\n",
      "R²  : 0.5808871744013624\n",
      "NZAUK_7\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 2532.3622017231924\n",
      "RMSE: 2979.959142272133\n",
      "R²  : 0.22709113015312088\n"
     ]
    }
   ],
   "source": [
    "for loc in df['Location_ID'].unique():\n",
    "    print(loc)\n",
    "    sub = df[df['Location_ID'] == loc] \n",
    "    sub = sub.drop_duplicates(subset=['Date'], keep='first').sort_values('Date').set_index('Date')# Important for the ARIMA model to function \n",
    "\n",
    "    y = sub['PedsSen_Count'].asfreq('D').interpolate()\n",
    "    x = sub[['Weather_Temperature',\n",
    "             'Weather_Wind_Gust',\n",
    "             'Weather_Relative_Humidity',\n",
    "             'Weather_Precipitation',\n",
    "             'Is_Holiday']].asfreq('D').interpolate()\n",
    "\n",
    "    y = y[(y.index <= end_trim_date) & (y.index >= str_trim_date)] # will change depending on new datasets in the future\n",
    "    x = x[(x.index <= end_trim_date) & (x.index >= str_trim_date)] # will change depending on new datasets in the future \n",
    "    print([x.shape,y.shape])\n",
    "\n",
    "    split = int(len(y) * 0.8) # keep chrno order \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    y_train = np.log1p(y.iloc[:split])\n",
    "    y_test  = y.iloc[split:]\n",
    "\n",
    "    x_train = scaler.fit_transform(x.iloc[:split])\n",
    "    x_test  = scaler.transform(x.iloc[split:])\n",
    "    # x_train = x.iloc[:split]\n",
    "    # x_test  = x.iloc[split:]\n",
    "\n",
    "    # # ARIMA parameters\n",
    "    stepwise = auto_arima(y=y_train, # Dep\n",
    "                      x=x_train, #Inp\n",
    "                      seasonal=True,\n",
    "                      m=7, # 7 day pattern\n",
    "                      trace=False,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      )\n",
    "    \n",
    "    # # SARIMAx model fitting\n",
    "    model = SARIMAX(endog=y_train, # Dep\n",
    "                    exog=x_train, # Indep\n",
    "                    order=stepwise.order, seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    day = 90 # 3 months\n",
    "    yt = y_test[:day]\n",
    "    start_date = yt.index[0] # using the date index \n",
    "    end_date   = yt.index[-1]\n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "\n",
    "    y_pred = results.predict(\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        exog=x_test[:day]\n",
    "    )\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    mae  = mean_absolute_error(yt, y_pred)\n",
    "    rmse = root_mean_squared_error(yt, y_pred)\n",
    "    r2   = r2_score(yt, y_pred)\n",
    "\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R²  :\", r2)\n",
    "    models[f'{loc}'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa8373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRDUB_1\n",
      "IRDUB_3\n",
      "IRDUB_4\n",
      "IRDUB_5\n",
      "IRDUB_8\n",
      "NZAUK_1\n",
      "NZAUK_5\n",
      "NZAUK_6\n",
      "NZAUK_7\n"
     ]
    }
   ],
   "source": [
    "for loc in df['Location_ID'].unique():\n",
    "    print(loc)\n",
    "    sub = df[df['Location_ID'] == loc] \n",
    "    sub = sub.drop_duplicates(subset=['Date'], keep='first').sort_values('Date').set_index('Date')# Important for the ARIMA model to function \n",
    "\n",
    "    y = sub['PedsSen_Count'].asfreq('D').interpolate()\n",
    "    x = sub[['Weather_Temperature',\n",
    "             'Weather_Wind_Gust',\n",
    "             'Weather_Relative_Humidity',\n",
    "             'Weather_Precipitation',\n",
    "             'Is_Holiday']].asfreq('D').interpolate()\n",
    "\n",
    "    y = y[(y.index <= end_trim_date) & (y.index >= str_trim_date)] # will change depending on new datasets in the future\n",
    "    x = x[(x.index <= end_trim_date) & (x.index >= str_trim_date)] # will change depending on new datasets in the future \n",
    "\n",
    "    split = int(len(y) * 0.8) # keep chrno order \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_ft = scaler.fit_transform(x)\n",
    "\n",
    "    # # ARIMA parameters\n",
    "    stepwise = auto_arima(y=y, # Dep\n",
    "                      x=x_ft, #Inp\n",
    "                      seasonal=True,\n",
    "                      m=7, # 7 day pattern\n",
    "                      trace=False,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      )\n",
    "    \n",
    "    # # SARIMAx model fitting\n",
    "    model = SARIMAX(endog=y, # Dep\n",
    "                    exog=x_ft, # Indep\n",
    "                    order=stepwise.order, seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    models2[f'{loc}'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc529969",
   "metadata": {},
   "source": [
    "### Save model pickel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba01ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"arima_models\", exist_ok=True) \n",
    "for loc,results in models.items():\n",
    "    # Save model\n",
    "    model_path = f\"arima_models/{loc}_arima.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9395d4",
   "metadata": {},
   "source": [
    "#### Use a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "855471b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error # <--- this is from Open Meteo Api Docs\n",
    "cache_session = requests_cache.CachedSession('.amriacache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c57526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather_Requester(lat:float,long:float) -> pd.DataFrame:\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\" # Histroical Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": '2024-12-31',\n",
    "        \"end_date\": (date.today()-timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_gusts_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"],\n",
    "        \"timezone\": \"auto\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    # Basically getting the data for the beginning of the trim point of Sep 30 2025 of the dataset to 1 day - current day   \n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T1 = dly.Variables(0).ValuesAsNumpy() # Np array's \n",
    "    W1 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R1 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P1 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    url = \"https://seasonal-api.open-meteo.com/v1/seasonal\" # Future Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"forecast_days\": 180,\n",
    "        \"timezone\": \"auto\",\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_speed_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T2 = dly.Variables(0).ValuesAsNumpy()\n",
    "    W2 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R2 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P2 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    T = np.concatenate((T1,T2))\n",
    "    W = np.concatenate((W1,W2))\n",
    "    P = np.concatenate((P1,P2))\n",
    "    R = np.concatenate((R1,R2))\n",
    "    \n",
    "    # Build the final indep array, holiday and time will be added later\n",
    "    vstk = pd.DataFrame(data = np.vstack((T,W,P,R)).T,\n",
    "                        columns=['Weather_Temperature',\n",
    "                                 'Weather_Wind_Gust',\n",
    "                                 'Weather_Relative_Humidity',\n",
    "                                 'Weather_Precipitation'])\n",
    "\n",
    "    return vstk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2556a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holidayer(df:pd.DataFrame,CCode:str) -> pd.DataFrame:\n",
    "    # Uses country code and each data to find holiday or not\n",
    "    df['Is_Holiday'] = df['Date'].apply(lambda x: 1 if hl.country_holidays(country=CCode).get(x) != None else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ba835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_mean\n",
      "2024-12-31     5151.169100\n",
      "2025-01-01     7346.382381\n",
      "2025-01-02    13171.440069\n",
      "2025-01-03    12505.571217\n",
      "2025-01-04    12466.297850\n",
      "...                    ...\n",
      "2026-08-14    20501.754710\n",
      "2026-08-15    19255.095954\n",
      "2026-08-16    17283.505984\n",
      "2026-08-17    19176.573700\n",
      "2026-08-18    17840.400913\n",
      "\n",
      "[596 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "loc = \"IRDUB_1\" # This was a location to be displayed to user\n",
    "with open(f\"arima_models/{loc}_arima.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f) # grab right pickel file\n",
    "\n",
    "d = datetime(2026,4,23).date()# User specfiies a date -- test\n",
    "w = Weather_Requester(53.3438,-6.254) # Grab weather from past and for future\n",
    "w.insert(4,'Is_Holiday',0)# Inserting these columns to match indep input\n",
    "w.insert(0,'Date',range(len(w))) # Use range to fill in date indexing numbers \n",
    "# Add in the date range from trim point 2026-01-01\n",
    "w['Date'] = w['Date'].apply(lambda x: datetime(2024,12,31).date() + timedelta(days=x))\n",
    "h = Holidayer(w,'IE') # Add in the holiday data\n",
    "h = h.set_index('Date').asfreq('D').interpolate(method='linear') # numeric only\n",
    "# Send to predict next set of days\n",
    "pred_mean = pd.DataFrame(np.expm1(model.get_forecast(exog=h,steps=len(h)).predicted_mean))\n",
    "print(pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c2abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-12-31 00:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_meancp = pred_mean.copy()\n",
    "idx = pred_meancp.index[:1][0] # deaaling with timestamps\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a0366f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2026-04-23 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.Timestamp(d) # convert user specified date\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "952e36a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40512.74278997395]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the forecasted crowd number at a date for a lcoation\n",
    "[pred_meancp['predicted_mean'].loc[f]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1870f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Timestamp('2026-03-24 00:00:00'), 43868.45914361098)\n",
      "(Timestamp('2026-03-25 00:00:00'), 43202.6233676457)\n",
      "(Timestamp('2026-03-26 00:00:00'), 44402.341829750614)\n",
      "(Timestamp('2026-03-27 00:00:00'), 47725.258501123855)\n",
      "(Timestamp('2026-03-28 00:00:00'), 45141.26912444328)\n",
      "(Timestamp('2026-03-29 00:00:00'), 40193.52326276475)\n",
      "(Timestamp('2026-03-30 00:00:00'), 42755.10146588258)\n",
      "(Timestamp('2026-03-31 00:00:00'), 41408.76720025946)\n",
      "(Timestamp('2026-04-01 00:00:00'), 39191.88358620869)\n",
      "(Timestamp('2026-04-02 00:00:00'), 36845.403083576166)\n",
      "(Timestamp('2026-04-03 00:00:00'), 39221.668052729554)\n",
      "(Timestamp('2026-04-04 00:00:00'), 41949.32670719112)\n",
      "(Timestamp('2026-04-05 00:00:00'), 40541.23341719048)\n",
      "(Timestamp('2026-04-06 00:00:00'), 43862.252579314576)\n",
      "(Timestamp('2026-04-07 00:00:00'), 46660.74835960026)\n",
      "(Timestamp('2026-04-08 00:00:00'), 39995.76508773631)\n",
      "(Timestamp('2026-04-09 00:00:00'), 41963.51438316489)\n",
      "(Timestamp('2026-04-10 00:00:00'), 43035.760145364344)\n",
      "(Timestamp('2026-04-11 00:00:00'), 42370.74081724442)\n",
      "(Timestamp('2026-04-12 00:00:00'), 36976.510202983416)\n",
      "(Timestamp('2026-04-13 00:00:00'), 39130.344825461805)\n",
      "(Timestamp('2026-04-14 00:00:00'), 43223.229462674215)\n",
      "(Timestamp('2026-04-15 00:00:00'), 43404.76017947315)\n",
      "(Timestamp('2026-04-16 00:00:00'), 41415.93206541026)\n",
      "(Timestamp('2026-04-17 00:00:00'), 42976.33322580385)\n",
      "(Timestamp('2026-04-18 00:00:00'), 40483.13544405309)\n",
      "(Timestamp('2026-04-19 00:00:00'), 35090.84996658764)\n",
      "(Timestamp('2026-04-20 00:00:00'), 34927.96639315898)\n",
      "(Timestamp('2026-04-21 00:00:00'), 37264.39991538982)\n",
      "(Timestamp('2026-04-22 00:00:00'), 36783.73702501214)\n",
      "(Timestamp('2026-04-23 00:00:00'), 40512.74278997395)\n",
      "(Timestamp('2026-04-24 00:00:00'), 38388.195927708395)\n",
      "(Timestamp('2026-04-25 00:00:00'), 37848.84746336909)\n",
      "(Timestamp('2026-04-26 00:00:00'), 35041.25566947173)\n",
      "(Timestamp('2026-04-27 00:00:00'), 38135.96919532351)\n",
      "(Timestamp('2026-04-28 00:00:00'), 39411.57071646108)\n",
      "(Timestamp('2026-04-29 00:00:00'), 35926.201562262686)\n",
      "(Timestamp('2026-04-30 00:00:00'), 33810.46373783494)\n",
      "(Timestamp('2026-05-01 00:00:00'), 35478.62106432873)\n",
      "(Timestamp('2026-05-02 00:00:00'), 35194.888046230175)\n",
      "(Timestamp('2026-05-03 00:00:00'), 28880.39631323334)\n"
     ]
    }
   ],
   "source": [
    "print(*pred_meancp['predicted_mean'].loc[f - timedelta(days=30):f + timedelta(days=10)].items(),sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
