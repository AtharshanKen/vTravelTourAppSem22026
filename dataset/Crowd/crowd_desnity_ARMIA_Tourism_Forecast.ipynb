{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3e116",
   "metadata": {},
   "source": [
    "# ARIMA\n",
    "- Produces Crowd Predicitions based on weather and user selected location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd456dd",
   "metadata": {},
   "source": [
    "### Load the Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebb45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from pmdarima import AutoARIMA,auto_arima\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime,timedelta,date\n",
    "import holidays as hl\n",
    "\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry\n",
    "str_trim_date = pd.to_datetime('2021-01-01').to_datetime64()# The start of the dataset\n",
    "end_trim_date = pd.to_datetime('2025-12-31').to_datetime64()# The end of the dataset, shouldn't assume both actual end at this date for each location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0fcfb",
   "metadata": {},
   "source": [
    "### Load the data set ensure both the dataframe date range and date are in correct format for ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auck_peds = pd.read_csv(\"data_weather/Final/Auckland_Pedestrian_daily.csv\")\n",
    "Dub_peds = pd.read_csv(\"data_weather/Final/Dublin_Pedestrian_daily.csv\")\n",
    "\n",
    "df = pd.concat([Auck_peds, Dub_peds],ignore_index=True)\n",
    "\n",
    "df['Date'] = df['Date'].apply(lambda x: pd.to_datetime(x).to_datetime64())\n",
    "df = df.sort_values(['Location_ID','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6258390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['2021-01-01T00:00:00.000000000', '2021-01-02T00:00:00.000000000',\n",
       "        '2021-01-03T00:00:00.000000000', ...,\n",
       "        '2025-12-29T00:00:00.000000000', '2025-12-30T00:00:00.000000000',\n",
       "        '2025-12-31T00:00:00.000000000'], dtype='datetime64[ns]')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df['Date'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f310aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([numpy.datetime64('2025-12-31T00:00:00.000000000')],\n",
       " [numpy.datetime64('2021-01-01T00:00:00.000000000')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[end_trim_date],[str_trim_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120d01",
   "metadata": {},
   "source": [
    "### Main ARIMA model\n",
    "- Model creation\n",
    "- Data splitting\n",
    "- Fitting model\n",
    "- Creates pickel files for each location\n",
    "    - Need seperate pickel files for forecasting each location \n",
    "- ARMIA needs to have even spacing between dates\n",
    "    if gap then a fill in needs to be done for Y values(Dep Var) & Exog(or X Ind Vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRDUB_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 29727.533457775684\n",
      "RMSE: 33920.8837994051\n",
      "R²  : -0.9522218701484291\n",
      "IRDUB_3\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 22485.45514220532\n",
      "RMSE: 25661.872200089394\n",
      "R²  : -1.1006789972823663\n",
      "IRDUB_4\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 26603.661096488384\n",
      "RMSE: 30911.153373521764\n",
      "R²  : -0.6212837079594891\n",
      "IRDUB_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 5494.530908943564\n",
      "RMSE: 6873.9828773365625\n",
      "R²  : 0.26864920080583177\n",
      "IRDUB_8\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 156512.6983646796\n",
      "RMSE: 166722.1696191833\n",
      "R²  : -4.678986933188882\n",
      "NZAUK_1\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 5805.350942499204\n",
      "RMSE: 7085.3636179820405\n",
      "R²  : 0.521310522908309\n",
      "NZAUK_5\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 20543.74602744719\n",
      "RMSE: 22626.185905700986\n",
      "R²  : -0.013747570443654489\n",
      "NZAUK_6\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 10306.830033665154\n",
      "RMSE: 11590.54202405199\n",
      "R²  : 0.08846885896144208\n",
      "NZAUK_7\n",
      "[(1826, 5), (1826,)]\n",
      "2024-12-31 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "MAE : 2767.4971245964134\n",
      "RMSE: 3252.667398708566\n",
      "R²  : 0.07915404290777917\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for loc in df['Location_ID'].unique():\n",
    "    print(loc)\n",
    "    sub = df[df['Location_ID'] == loc] \n",
    "    sub = sub.drop_duplicates(subset=['Date'], keep='first').sort_values('Date').set_index('Date')# Important for the ARIMA model to function \n",
    "\n",
    "    y = sub['PedsSen_Count'].asfreq('D').interpolate()\n",
    "    x = sub[['Weather_Temperature',\n",
    "             'Weather_Wind_Gust',\n",
    "             'Weather_Relative_Humidity',\n",
    "             'Weather_Precipitation',\n",
    "             'Is_Holiday']].asfreq('D').interpolate()\n",
    "\n",
    "    y = y[(y.index <= end_trim_date) & (y.index >= str_trim_date)] # will change depending on new datasets in the future\n",
    "    x = x[(x.index <= end_trim_date) & (x.index >= str_trim_date)] # will change depending on new datasets in the future \n",
    "    print([x.shape,y.shape])\n",
    "\n",
    "    split = int(len(y) * 0.8) # keep chrno order \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    y_train = y.iloc[:split]\n",
    "    y_test  = y.iloc[split:]\n",
    "\n",
    "    x_train = scaler.fit_transform(x.iloc[:split])\n",
    "    x_test  = scaler.transform(x.iloc[split:])\n",
    "    # x_train = x.iloc[:split]\n",
    "    # x_test  = x.iloc[split:]\n",
    "\n",
    "    # # ARIMA parameters\n",
    "    stepwise = auto_arima(y=y_train, # Dep\n",
    "                      x=x_train, #Inp\n",
    "                      seasonal=True,\n",
    "                      m=7, # 7 day pattern\n",
    "                      trace=False,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      )\n",
    "    \n",
    "    # # SARIMAx model fitting\n",
    "    model = SARIMAX(endog=y_train, # Dep\n",
    "                    exog=x_train, # Indep\n",
    "                    order=stepwise.order, seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    day = 90 # 3 months\n",
    "    yt = y_test[:day]\n",
    "    start_date = yt.index[0] # using the date index \n",
    "    end_date   = yt.index[-1]\n",
    "    print(start_date)\n",
    "    print(end_date)\n",
    "\n",
    "    y_pred = results.predict(\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        exog=x_test[:day]\n",
    "    )\n",
    "\n",
    "    mae  = mean_absolute_error(yt, y_pred)\n",
    "    rmse = root_mean_squared_error(yt, y_pred)\n",
    "    r2   = r2_score(yt, y_pred)\n",
    "\n",
    "    print(\"MAE :\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R²  :\", r2)\n",
    "    models[f'{loc}'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa8373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = models.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672a7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRDUB_1\n",
      "IRDUB_3\n",
      "IRDUB_4\n",
      "IRDUB_5\n",
      "IRDUB_8\n",
      "NZAUK_1\n",
      "NZAUK_5\n",
      "NZAUK_6\n",
      "NZAUK_7\n"
     ]
    }
   ],
   "source": [
    "for loc in df['Location_ID'].unique():\n",
    "    print(loc)\n",
    "    sub = df[df['Location_ID'] == loc] \n",
    "    sub = sub.drop_duplicates(subset=['Date'], keep='first').sort_values('Date').set_index('Date')# Important for the ARIMA model to function \n",
    "\n",
    "    y = sub['PedsSen_Count'].asfreq('D').interpolate()\n",
    "    x = sub[['Weather_Temperature',\n",
    "             'Weather_Wind_Gust',\n",
    "             'Weather_Relative_Humidity',\n",
    "             'Weather_Precipitation',\n",
    "             'Is_Holiday']].asfreq('D').interpolate()\n",
    "\n",
    "    y = y[(y.index <= end_trim_date) & (y.index >= str_trim_date)] # will change depending on new datasets in the future\n",
    "    x = x[(x.index <= end_trim_date) & (x.index >= str_trim_date)] # will change depending on new datasets in the future \n",
    "\n",
    "    split = int(len(y) * 0.8) # keep chrno order \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_ft = scaler.fit_transform(x)\n",
    "\n",
    "    # # ARIMA parameters\n",
    "    stepwise = auto_arima(y=y, # Dep\n",
    "                      x=x_ft, #Inp\n",
    "                      seasonal=True,\n",
    "                      m=7, # 7 day pattern\n",
    "                      trace=False,\n",
    "                      error_action='ignore',\n",
    "                      suppress_warnings=True,\n",
    "                      )\n",
    "    \n",
    "    # # SARIMAx model fitting\n",
    "    model = SARIMAX(endog=y, # Dep\n",
    "                    exog=x_ft, # Indep\n",
    "                    order=stepwise.order, seasonal_order=stepwise.seasonal_order,\n",
    "                    enforce_stationarity=False, # Variance and trends aren't constant set to false\n",
    "                    enforce_invertibility=False)\n",
    "    results = model.fit(disp=False)\n",
    "\n",
    "    models2[f'{loc}'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc529969",
   "metadata": {},
   "source": [
    "### Save model pickel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"arima_models\", exist_ok=True) \n",
    "for loc,results in models2.items():\n",
    "    # Save model\n",
    "    model_path = f\"arima_models/{loc}_arima.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9395d4",
   "metadata": {},
   "source": [
    "#### Use a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855471b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error # <--- this is from Open Meteo Api Docs\n",
    "cache_session = requests_cache.CachedSession('.amriacache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c57526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather_Requester(lat:float,long:float) -> pd.DataFrame:\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\" # Histroical Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": '2026-01-01',\n",
    "        \"end_date\": (date.today()-timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_gusts_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"],\n",
    "        \"timezone\": \"auto\",\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    # Basically getting the data for the beginning of the trim point of Sep 30 2025 of the dataset to 1 day - current day   \n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T1 = dly.Variables(0).ValuesAsNumpy() # Np array's \n",
    "    W1 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R1 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P1 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    url = \"https://seasonal-api.open-meteo.com/v1/seasonal\" # Future Data\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"forecast_days\": 180,\n",
    "        \"timezone\": \"auto\",\n",
    "        \"daily\": [\"temperature_2m_mean\", \"wind_speed_10m_mean\", \"relative_humidity_2m_mean\", \"precipitation_sum\"]\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "    dly = responses[0].Daily()\n",
    "\n",
    "    T2 = dly.Variables(0).ValuesAsNumpy()\n",
    "    W2 = dly.Variables(1).ValuesAsNumpy()\n",
    "    R2 = dly.Variables(2).ValuesAsNumpy()\n",
    "    P2 = dly.Variables(3).ValuesAsNumpy()\n",
    "\n",
    "    T = np.concatenate((T1,T2))\n",
    "    W = np.concatenate((W1,W2))\n",
    "    P = np.concatenate((P1,P2))\n",
    "    R = np.concatenate((R1,R2))\n",
    "    \n",
    "    # Build the final indep array, holiday and time will be added later\n",
    "    vstk = pd.DataFrame(data = np.vstack((T,W,P,R)).T,\n",
    "                        columns=['Weather_Temperature',\n",
    "                                 'Weather_Wind_Gust',\n",
    "                                 'Weather_Relative_Humidity',\n",
    "                                 'Weather_Precipitation'])\n",
    "\n",
    "    return vstk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2556a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holidayer(df:pd.DataFrame,CCode:str) -> pd.DataFrame:\n",
    "    # Uses country code and each data to find holiday or not\n",
    "    df['Is_Holiday'] = df['Date'].apply(lambda x: 1 if hl.country_holidays(country=CCode).get(x) != None else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_mean\n",
      "2024-12-31   -54882.062426\n",
      "2025-01-01   -42565.222219\n",
      "2025-01-02   -31969.317049\n",
      "2025-01-03   -37592.613082\n",
      "2025-01-04   -56649.141805\n",
      "...                    ...\n",
      "2026-07-31    27936.884445\n",
      "2026-08-01    19706.811214\n",
      "2026-08-02    16321.795412\n",
      "2026-08-03    21481.221231\n",
      "2026-08-04    24177.361517\n",
      "\n",
      "[582 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "loc = \"NZAUK_1\" # This was a location to be displayed to user\n",
    "with open(f\"arima_models/{loc}_arima.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f) # grab right pickel file\n",
    "\n",
    "d = datetime(2026,4,23).date()# User specfiies a date -- test\n",
    "w = Weather_Requester(-36.8485,174.7633) # Grab weather from past and for future\n",
    "w.insert(4,'Is_Holiday',0)# Inserting these columns to match indep input\n",
    "w.insert(0,'Date',range(len(w))) # Use range to fill in date indexing numbers \n",
    "# Add in the date range from trim point 2026-01-01\n",
    "w['Date'] = w['Date'].apply(lambda x: datetime(2026,1,1).date() + timedelta(days=x))\n",
    "h = Holidayer(w,'IE') # Add in the holiday data\n",
    "h = h.set_index('Date').asfreq('D').interpolate(method='linear') # numeric only\n",
    "# Send to predict next set of days\n",
    "pred_mean = pd.DataFrame(model.get_forecast(exog=h,steps=len(h)).predicted_mean)\n",
    "print(pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c2abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-12-31 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_meancp = pred_mean.copy()\n",
    "idx = pred_meancp.index[:1][0] # deaaling with timestamps\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0366f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2026-04-23 00:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.Timestamp(d) # convert user specified date\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952e36a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15957.129645256318]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the forecasted crowd number at a date for a lcoation\n",
    "[pred_meancp['predicted_mean'].loc[f]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1870f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Timestamp('2026-03-24 00:00:00'), 4761.584269763247)\n",
      "(Timestamp('2026-03-25 00:00:00'), 6169.702203966124)\n",
      "(Timestamp('2026-03-26 00:00:00'), 10125.851482163016)\n",
      "(Timestamp('2026-03-27 00:00:00'), 7675.329893704147)\n",
      "(Timestamp('2026-03-28 00:00:00'), 2431.9421352268837)\n",
      "(Timestamp('2026-03-29 00:00:00'), -657.4489785312471)\n",
      "(Timestamp('2026-03-30 00:00:00'), 6450.841516207292)\n",
      "(Timestamp('2026-03-31 00:00:00'), 8554.623450077459)\n",
      "(Timestamp('2026-04-01 00:00:00'), 7375.255735907071)\n",
      "(Timestamp('2026-04-02 00:00:00'), 10961.666365855323)\n",
      "(Timestamp('2026-04-03 00:00:00'), 10930.963591254316)\n",
      "(Timestamp('2026-04-04 00:00:00'), 7457.410590832056)\n",
      "(Timestamp('2026-04-05 00:00:00'), -1130.8428918880018)\n",
      "(Timestamp('2026-04-06 00:00:00'), -79.22915839323105)\n",
      "(Timestamp('2026-04-07 00:00:00'), 3984.8621916948105)\n",
      "(Timestamp('2026-04-08 00:00:00'), 4264.681326681872)\n",
      "(Timestamp('2026-04-09 00:00:00'), 11103.390386679675)\n",
      "(Timestamp('2026-04-10 00:00:00'), 10961.68851710682)\n",
      "(Timestamp('2026-04-11 00:00:00'), 6991.328871942016)\n",
      "(Timestamp('2026-04-12 00:00:00'), 521.6748751116829)\n",
      "(Timestamp('2026-04-13 00:00:00'), 7153.201538033703)\n",
      "(Timestamp('2026-04-14 00:00:00'), 3674.468467068502)\n",
      "(Timestamp('2026-04-15 00:00:00'), 5609.735065464818)\n",
      "(Timestamp('2026-04-16 00:00:00'), 12656.946289622792)\n",
      "(Timestamp('2026-04-17 00:00:00'), 14004.099765871084)\n",
      "(Timestamp('2026-04-18 00:00:00'), 9216.145726545532)\n",
      "(Timestamp('2026-04-19 00:00:00'), 8276.83244551772)\n",
      "(Timestamp('2026-04-20 00:00:00'), 10325.212732133528)\n",
      "(Timestamp('2026-04-21 00:00:00'), 9276.779137977312)\n",
      "(Timestamp('2026-04-22 00:00:00'), 8602.672903443665)\n",
      "(Timestamp('2026-04-23 00:00:00'), 15957.129645256318)\n",
      "(Timestamp('2026-04-24 00:00:00'), 15119.98416384164)\n",
      "(Timestamp('2026-04-25 00:00:00'), 10538.929652171828)\n",
      "(Timestamp('2026-04-26 00:00:00'), 7293.000085904379)\n",
      "(Timestamp('2026-04-27 00:00:00'), 10695.076732818685)\n",
      "(Timestamp('2026-04-28 00:00:00'), 13210.944533815164)\n",
      "(Timestamp('2026-04-29 00:00:00'), 13417.314840326355)\n",
      "(Timestamp('2026-04-30 00:00:00'), 19788.22008132963)\n",
      "(Timestamp('2026-05-01 00:00:00'), 14711.84958387151)\n",
      "(Timestamp('2026-05-02 00:00:00'), 8915.731857105719)\n",
      "(Timestamp('2026-05-03 00:00:00'), 4995.254900218992)\n"
     ]
    }
   ],
   "source": [
    "print(*pred_meancp['predicted_mean'].loc[f - timedelta(days=30):f + timedelta(days=10)].items(),sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
